# ğŸ“‚ File Crawler with Generator (Advanced++)

A powerful, pluggable file crawler built in Python that scans through `.txt` and `.log` files inside any directory and yields lines containing a specific keyword. Uses:

- âœ… Abstract Base Classes (`ABC`)
- âœ… Python Generators (`yield`)
- âœ… Decorators for performance logging
- âœ… CLI interface (`argparse`)
- âœ… Clean modular file-by-file structure

---

## ğŸš€ Features

- Crawl directories recursively for `.txt` and `.log` files
- Search for specific keywords (case-insensitive)
- Yield matching lines with file path and line number
- Log performance using a decorator
- Simple command-line usage

---

## ğŸ“ Project Structure

file_crawler/
â”œâ”€â”€ base_crawler.py # Abstract class for pluggable crawlers
â”œâ”€â”€ keyword_crawler.py # Keyword search implementation
â”œâ”€â”€ decorators.py # Performance logger
â”œâ”€â”€ utils.py # Print helpers
â”œâ”€â”€ main.py # CLI interface


---

## ğŸ“¦ Requirements

- Python 3.7+
- No external dependencies

---

## ğŸ’» Usage

### Run from terminal:

```bash
python main.py <directory_path> <keyword>

```
## Example

python main.py ./logs error

## Output

./logs/server.log [Line 42]: Unexpected error occurred
./logs/server.log [Line 79]: Connection error with database

[INFO] Finished in 0.11 seconds.


## ğŸ§  Concepts Covered
- Abstract Classes: Easily extendable crawlers using BaseCrawler

- Generators: Efficient memory usage with yield for large file scans

- Decorators: Reusable performance logger

- File I/O: Safe reading with encoding fallback

- CLI Tools: Built with argparse for flexibility

## ğŸ§° Extend This Project
You can add more crawlers by subclassing BaseCrawler:

class RegexCrawler(BaseCrawler):
    def crawl(self, pattern: str):
        ...

## ğŸ“œ License
MIT License â€” Free to use and modify.

## âœï¸ Author
Built as an advanced Python exercise on abstract design and generators.